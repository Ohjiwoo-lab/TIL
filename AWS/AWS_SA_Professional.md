
-----------------------

### #1

솔루션 설계자는 회사에서 곧 출시할 새 애플리케이션을 위한 데이터 저장 및 검색 아키텍처를 설계하고 있습니다. 이 애플리케이션은 전 세계 장치에서 분당 수백만 개의 작은 레코드를 수집하도록 설계되었습니다. 각 레코드의 크기는 4KB 미만이며 짧은 대기 시간으로 검색할 수 있는 내구성 있는 위치에 저장되어야 합니다. 데이터는 일시적이며 회사는 120일 동안만 데이터를 저장해야 하며 그 이후에는 데이터가 삭제될 수 있습니다. 

솔루션 설계자는 1년 동안 스토리지 요구 사항이 약 10~15TB가 될 것으로 계산합니다.

가장 비용 효율적이고 설계 요구 사항을 충족하는 스토리지 전략은 무엇입니까?

- A. 인덱싱된 검색을 허용하기 위해 각 수신 레코드를 Amazon S3 버킷에 단일 .csv 파일로 저장하도록 애플리케이션을 설계합니다. 120일이 지난 데이터를 삭제하도록 수명 주기 정책을 구성합니다.

- B. 규모에 맞게 적절하게 구성된 Amazon DynamoDB 테이블에 각 수신 레코드를 저장하도록 애플리케이션을 설계합니다. 120일보다 오래된 레코드를 삭제하도록 DynamoDB TTL(Time to Live) 기능을 구성합니다.

- C. 각 수신 레코드를 Amazon RDS MySQL 데이터베이스의 단일 테이블에 저장하도록 애플리케이션을 설계합니다. 120일보다 오래된 레코드를 삭제하는 쿼리를 실행하는 야간 크론 작업을 실행합니다.

- D. 수신 레코드를 Amazon S3 버킷에 쓰기 전에 일괄 처리하도록 애플리케이션을 설계합니다. 배치의 레코드 목록을 포함하도록 객체의 메타데이터를 업데이트하고 Amazon S3 메타데이터 검색 기능을 사용하여 데이터를 검색합니다. 120일 후에 데이터를 삭제하도록 수명 주기 정책을 구성합니다.

<details>
   <summary> <b> 문제 풀이 확인 (👈click!) </b> </summary>

<br/>

이는 데이터를 저장할 적절한 스토리지를 선택하는 문제이다. 요구 사항을 더 살펴보면 저장할 데이터는 `분당 수백만 개`가 생성되는 `크기가 작은` 레코드이며, 짧은 대기 시간으로 `검색`할 수 있어야 하고, `내구성`이 있는 위치여야 하며, 120일이 지난 후 `삭제`되어야 한다. 또한 1년 동안 `10~15TB` 정도의 꽤 많은 양의 데이터를 저장해야 하고, `비용`이 가장 적게 들어야 한다.

보기를 보면 스토리지 후보로 `S3`, `DynamoDB`, `RDS MySQL`이 제시되었다. S3부터 살펴보자.

S3는 무한히 확장할 수 있기 때문에 10~15TB의 저장 공간 요구사항을 충족하고, 99.999999999%의 데이터 내구성을 가지고 있어 저장된 데이터가 손실될 걱정은 할 필요가 없다. 또한 수명주기 정책을 통해 120일이 지난 후 자동으로 데이터가 삭제되도록 할 수 있으며, 비용 효율적인 스토리지이다.

하지만 작은 파일을 많이 저장하거나, 검색 기능을 충족하지는 못한다. S3에 크기가 작은 파일을 많이 저장하는 것이 권장되지 않는 이유는 S3 객체에 대한 GET 요청 제한 때문이다. S3에서는 접두상 1개 당 초 당 5500개의 GET 요청을 할 수 있다. 만약 S3에 크기가 작은 파일들을 수백 만개 저장해두고 있었다면, 서비스를 제공하기 위해 빈번한 GET 요청이 이루어질 것이고 이로 인해 제한을 받을 수 있기 때문에 되도록 크기가 작은 파일을 많이 저장하는 경우 S3는 좋지 못한 선택지이다.

또한 S3는 속성 기반 검색을 제공해주지 않는다. S3 Select를 통해 S3에 저장된 데이터의 일부분을 필터링하여 결과를 반환할 수 있는 기능이 존재하긴 하지만, 데이터 형식이 JSON, CSV 등으로 제한되어 있고 하나의 데이터를 검색하기 위해 일일히 SQL 쿼리문을 작성해야 한다는 불편함이 있다. 그래서 S3에서 데이터를 검색하기 위해서는 DynamoDB 테이블에 객체에 대한 메타데이터를 저장하는 방식이 있다. 아키텍처는 다음과 같을 것이다.

![image](https://github.com/Ohjiwoo-lab/TIL/assets/74577768/271d6136-e0a5-43f4-9f1e-75b8921327c6)   
출처: [Building and Maintaining an Amazon S3 Metadata Index without Servers](https://aws.amazon.com/ko/blogs/big-data/building-and-maintaining-an-amazon-s3-metadata-index-without-servers/)

S3에 데이터가 업로드되면 S3 Events를 통해 Lambda 함수를 트리거한다. 그러면 Lambda 함수는 업로드된 객체의 메타데이터를 추출하여 검색 가능한 인덱스를 DynamoDB 테이블에 저장한다. 그러면 추후 DynamoDB 테이블을 통해 객체를 검색할 수 있게 된다.

A에서는 인덱싱된 검색을 위해 CSV 파일에 모든 데이터를 저장하도록 설계한다고 했는데, 이는 S3 Select를 이용하기 위함이다. 이는 분명 가능한 선택지이기는 하지만 분당 수백만 개씩 생성되는 데이터를 CSV 파일에 저장하기 위해 일일히 변환 작업을 수행해야 하고, 데이터를 검색할 때에도 SQL 쿼리문을 작성해야 한다는 점에서 시간이 오래 걸리고 많은 비용이 발생할 것이다. 따라서 적합하지 않다.

D에서는 메타 데이터 검색 기능을 사용한다고 되어 있는데, 이는 S3에서 제공해주지 않는 기능이기 때문에 옳은 선택지가 아니다.

다음으로 RDS MySQL은 범용 SSD를 사용하는 경우 20GiB~64TiB의 용량을 제공해줄 수 있기 때문에 저장 공간 요구사항을 충족하고, 높은 내구성과 검색 기능도 충족한다. 하지만 RDS는 비용이 상당히 비싼 서비스이며 데이터를 자동으로 삭제해주는 기능을 제공해주지 못한다.

C에서 야간 크론 작업을 통해 데이터를 120일 후에 자동으로 삭제하도록 구성한다고 했는데, 물론 가능한 작업이지만 매번 크론 작업을 실행하는 데에 비용이 추가로 발생할 것이며 운영하기에도 복잡할 것이다. C는 비용 측면이나 운영 측면에서도 모두 효율적이지 못한 선택지이다.

따라서 정답은 B가 된다. DynamoDB는 분당 수백만 개씩 생성되는 데이터에 맞게 빠르게 확장할 수 있고, AWS에 의해 기본적으로 내구성이 보장되며, 모든 규모에서 10밀리초 미만의 짧은 대기 시간을 제공한다. 사용자가 정의한 프라이머리 키를 이용한 GET 작업과, 글로벌 보조 인덱스와 로컬 보조 인덱스를 통해 키가 아닌 속성 기반으로 검색할 수 있고, TTL 기능을 통해 일정 시간이 지난 후 데이터가 삭제되도록 설정할 수 있다. DynamoDB는 S3와 다르게 항목의 최대 크기가 400KB를 초과할 수 없다. 즉, 크기가 작은 데이터를 많이 저장하기에 적합한 스토리지인 것이다. 또한 서버리스 서비스이기 때문에 사용한 만큼만 비용을 지불하면 되어 비용 측면에서도 효율적이다.

따라서 DynamoDB가 해당 문제의 가장 적합한 스토리지이다.


</details>

-----------------------

<br />